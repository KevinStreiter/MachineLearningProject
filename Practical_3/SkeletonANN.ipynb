{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 3: Artificial Neural Network\n",
    "\n",
    "This is the first task of Practical 3. You will build a neural network to classify the handwritten digits from the MNIST dataset (http://yann.lecun.com/exdb/mnist/). \n",
    "You will build the classifier from scartch. \n",
    "\n",
    "We will mark your code based on the accuracy of your model. You should get **at least 97%** accuracy on this dataset. Don't forget to save and check in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara Dataset\n",
    "In this block, you will prepare the data for the training, such as normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data():\n",
    "    # load data\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # create validation data\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "    \n",
    "    # normalize\n",
    "    x_train =  x_train/255.0\n",
    "    x_val = x_val/255.0\n",
    "    x_test = x_test/255.0\n",
    "    \n",
    "    # Converts a class vector (integers) to one-hot encoding matrix.\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=10)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model\n",
    "\n",
    "Build and train your model. Finetuning with Hyperas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def create_model(x_train, y_train, x_val, y_val):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "    model.add(keras.layers.Dense({{choice([256, 512])}}, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.Activation({{choice(['relu', 'selu', 'elu'])}}))\n",
    "    model.add(keras.layers.Dropout({{uniform(0, 1)}}))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense({{choice([32, 64, 128])}}, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.Activation({{choice(['relu', 'selu', 'elu'])}}))\n",
    "    model.add(keras.layers.Dropout({{uniform(0, 1)}}))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr={{choice([1e-4, 1e-3, 1e-2, 1e-1])}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{choice([1e-4, 1e-3, 1e-2, 1e-1])}})\n",
    "    sgd = keras.optimizers.SGD(lr={{choice([1e-4, 1e-3, 1e-2, 1e-1])}})\n",
    "\n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optimizer = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optimizer = rmsprop\n",
    "    else:\n",
    "        optimizer = sgd\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer=optimizer)\n",
    "    \n",
    "    \n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size={{choice([32, 64, 128, 256])}},\n",
    "              epochs={{choice([2, 5, 10, 20, 30, 40])}},\n",
    "              verbose=2,\n",
    "              validation_data=(x_val,y_val))\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    \n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, \n",
    "    'model': model,  'history.val_loss':result.history['val_loss'], 'history.val_acc': result.history['val_accuracy'],\n",
    "    'history.loss': result.history['loss'], 'history.acc': result.history['accuracy']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [256, 512]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'selu', 'elu']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [32, 64, 128]),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'selu', 'elu']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'lr': hp.choice('lr', [1e-4, 1e-3, 1e-2, 1e-1]),\n",
      "        'lr_1': hp.choice('lr_1', [1e-4, 1e-3, 1e-2, 1e-1]),\n",
      "        'lr_2': hp.choice('lr_2', [1e-4, 1e-3, 1e-2, 1e-1]),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'sgd', 'rmsprop']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64, 128, 256]),\n",
      "        'epochs': hp.choice('epochs', [2, 5, 10, 20, 30, 40]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: # load data\n",
      "  3: (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "  4: \n",
      "  5: # create validation data\n",
      "  6: x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
      "  7: \n",
      "  8: # normalize\n",
      "  9: x_train =  x_train/255.0\n",
      " 10: x_val = x_val/255.0\n",
      " 11: x_test = x_test/255.0\n",
      " 12: \n",
      " 13: # Converts a class vector (integers) to one-hot encoding matrix.\n",
      " 14: y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
      " 15: y_val = keras.utils.to_categorical(y_val, num_classes=10)\n",
      " 16: y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
      " 17: \n",
      " 18: \n",
      " 19: \n",
      " 20: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     model = keras.models.Sequential()\n",
      "   4:     model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
      "   5:     model.add(keras.layers.Dense(space['Dense'], kernel_initializer=\"he_normal\"))\n",
      "   6:     model.add(keras.layers.Activation(space['Activation']))\n",
      "   7:     model.add(keras.layers.Dropout(space['Dropout']))\n",
      "   8:     model.add(keras.layers.BatchNormalization())\n",
      "   9:     model.add(keras.layers.Dense(space['Dense_1'], kernel_initializer=\"he_normal\"))\n",
      "  10:     model.add(keras.layers.Activation(space['Activation_1']))\n",
      "  11:     model.add(keras.layers.Dropout(space['Dropout_1']))\n",
      "  12:     model.add(keras.layers.BatchNormalization())\n",
      "  13:     \n",
      "  14:     model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
      "  15:     \n",
      "  16:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  17:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
      "  18:     sgd = keras.optimizers.SGD(lr=space['lr_2'])\n",
      "  19: \n",
      "  20:     choiceval = space['choiceval']\n",
      "  21:     if choiceval == 'adam':\n",
      "  22:         optimizer = adam\n",
      "  23:     elif choiceval == 'rmsprop':\n",
      "  24:         optimizer = rmsprop\n",
      "  25:     else:\n",
      "  26:         optimizer = sgd\n",
      "  27: \n",
      "  28:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
      "  29:                   optimizer=optimizer)\n",
      "  30:     \n",
      "  31:     \n",
      "  32: \n",
      "  33:     result = model.fit(x_train, y_train,\n",
      "  34:               batch_size=space['batch_size'],\n",
      "  35:               epochs=space['epochs'],\n",
      "  36:               verbose=2,\n",
      "  37:               validation_data=(x_val,y_val))\n",
      "  38:     \n",
      "  39:     validation_acc = np.amax(result.history['val_accuracy'])\n",
      "  40:     \n",
      "  41:     return {'loss': -validation_acc, 'status': STATUS_OK, \n",
      "  42:     'model': model,  'history.val_loss':result.history['val_loss'], 'history.val_acc': result.history['val_accuracy'],\n",
      "  43:     'history.loss': result.history['loss'], 'history.acc': result.history['accuracy']}\n",
      "  44: \n",
      "Epoch 1/20                                            \n",
      "750/750 - 4s - loss: 0.6327 - accuracy: 0.8095 - val_loss: 0.2827 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 2/20                                            \n",
      "750/750 - 4s - loss: 0.3315 - accuracy: 0.9049 - val_loss: 0.2126 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 3/20                                            \n",
      "750/750 - 4s - loss: 0.2618 - accuracy: 0.9250 - val_loss: 0.1788 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 4/20                                            \n",
      "750/750 - 4s - loss: 0.2228 - accuracy: 0.9359 - val_loss: 0.1579 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 5/20                                            \n",
      "750/750 - 4s - loss: 0.1968 - accuracy: 0.9423 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 6/20                                            \n",
      "750/750 - 4s - loss: 0.1730 - accuracy: 0.9484 - val_loss: 0.1324 - val_accuracy: 0.9608\n",
      "\n",
      "Epoch 7/20                                            \n",
      "750/750 - 4s - loss: 0.1541 - accuracy: 0.9543 - val_loss: 0.1240 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 8/20                                            \n",
      "750/750 - 4s - loss: 0.1455 - accuracy: 0.9570 - val_loss: 0.1183 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 9/20                                            \n",
      "750/750 - 4s - loss: 0.1322 - accuracy: 0.9611 - val_loss: 0.1118 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 10/20                                           \n",
      "750/750 - 4s - loss: 0.1236 - accuracy: 0.9636 - val_loss: 0.1068 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 11/20                                           \n",
      "750/750 - 4s - loss: 0.1157 - accuracy: 0.9656 - val_loss: 0.1048 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 12/20                                           \n",
      "750/750 - 4s - loss: 0.1072 - accuracy: 0.9685 - val_loss: 0.1031 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 13/20                                           \n",
      "750/750 - 4s - loss: 0.0985 - accuracy: 0.9701 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 14/20                                           \n",
      "750/750 - 3s - loss: 0.0932 - accuracy: 0.9723 - val_loss: 0.0960 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 15/20                                           \n",
      "750/750 - 3s - loss: 0.0861 - accuracy: 0.9739 - val_loss: 0.0938 - val_accuracy: 0.9720\n",
      "\n",
      "Epoch 16/20                                           \n",
      "750/750 - 4s - loss: 0.0855 - accuracy: 0.9746 - val_loss: 0.0922 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 17/20                                           \n",
      "750/750 - 4s - loss: 0.0795 - accuracy: 0.9754 - val_loss: 0.0918 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 18/20                                           \n",
      "750/750 - 4s - loss: 0.0753 - accuracy: 0.9768 - val_loss: 0.0906 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 19/20                                           \n",
      "750/750 - 4s - loss: 0.0689 - accuracy: 0.9789 - val_loss: 0.0900 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 20/20                                           \n",
      "750/750 - 3s - loss: 0.0672 - accuracy: 0.9794 - val_loss: 0.0889 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 1/30                                                                       \n",
      "750/750 - 6s - loss: 2.1487 - accuracy: 0.1760 - val_loss: 1.4043 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 2/30                                                                       \n",
      "750/750 - 5s - loss: 2.0592 - accuracy: 0.1910 - val_loss: 1.3758 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 3/30                                                                       \n",
      "750/750 - 5s - loss: 2.0343 - accuracy: 0.1933 - val_loss: 1.2455 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 4/30                                                                       \n",
      "750/750 - 5s - loss: 2.0134 - accuracy: 0.1960 - val_loss: 1.1561 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 5/30                                                                       \n",
      "750/750 - 6s - loss: 2.0026 - accuracy: 0.1977 - val_loss: 1.1291 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 6/30                                                                       \n",
      "750/750 - 7s - loss: 1.9966 - accuracy: 0.1969 - val_loss: 1.0970 - val_accuracy: 0.8178\n",
      "\n",
      "Epoch 7/30                                                                       \n",
      "750/750 - 5s - loss: 1.9957 - accuracy: 0.1980 - val_loss: 1.1365 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 8/30                                                                       \n",
      "750/750 - 5s - loss: 1.9938 - accuracy: 0.1996 - val_loss: 1.1355 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 9/30                                                                       \n",
      "750/750 - 5s - loss: 1.9892 - accuracy: 0.1976 - val_loss: 1.1561 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 10/30                                                                      \n",
      "750/750 - 5s - loss: 1.9827 - accuracy: 0.2054 - val_loss: 1.0595 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 11/30                                                                      \n",
      "750/750 - 5s - loss: 1.9880 - accuracy: 0.1995 - val_loss: 1.1197 - val_accuracy: 0.8332\n",
      "\n",
      "Epoch 12/30                                                                      \n",
      "750/750 - 5s - loss: 1.9819 - accuracy: 0.1994 - val_loss: 1.0711 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 13/30                                                                      \n",
      "750/750 - 5s - loss: 1.9773 - accuracy: 0.2016 - val_loss: 0.9761 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 14/30                                                                      \n",
      "750/750 - 5s - loss: 1.9826 - accuracy: 0.2031 - val_loss: 1.0853 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 15/30                                                                      \n",
      "750/750 - 5s - loss: 1.9785 - accuracy: 0.2077 - val_loss: 1.1063 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 16/30                                                                      \n",
      "750/750 - 5s - loss: 1.9717 - accuracy: 0.2055 - val_loss: 1.0360 - val_accuracy: 0.8916\n",
      "\n",
      "Epoch 17/30                                                                      \n",
      "750/750 - 5s - loss: 1.9766 - accuracy: 0.2090 - val_loss: 1.0080 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 18/30                                                                      \n",
      "750/750 - 5s - loss: 1.9737 - accuracy: 0.2073 - val_loss: 1.0353 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 19/30                                                                      \n",
      "750/750 - 5s - loss: 1.9727 - accuracy: 0.2068 - val_loss: 1.0561 - val_accuracy: 0.8578\n",
      "\n",
      "Epoch 20/30                                                                      \n",
      "750/750 - 5s - loss: 1.9702 - accuracy: 0.2100 - val_loss: 1.2139 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 21/30                                                                      \n",
      "750/750 - 5s - loss: 1.9720 - accuracy: 0.2087 - val_loss: 1.0711 - val_accuracy: 0.8525\n",
      "\n",
      "Epoch 22/30                                                                      \n",
      "750/750 - 5s - loss: 1.9663 - accuracy: 0.2082 - val_loss: 1.1992 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 23/30                                                                      \n",
      "750/750 - 5s - loss: 1.9715 - accuracy: 0.2081 - val_loss: 1.2054 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 24/30                                                                      \n",
      "750/750 - 5s - loss: 1.9666 - accuracy: 0.2076 - val_loss: 1.0193 - val_accuracy: 0.8567\n",
      "\n",
      "Epoch 25/30                                                                      \n",
      "750/750 - 5s - loss: 1.9688 - accuracy: 0.2068 - val_loss: 1.1992 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 26/30                                                                      \n",
      "750/750 - 5s - loss: 1.9646 - accuracy: 0.2131 - val_loss: 1.0474 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 27/30                                                                      \n",
      "750/750 - 5s - loss: 1.9650 - accuracy: 0.2107 - val_loss: 1.0206 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 28/30                                                                      \n",
      "750/750 - 5s - loss: 1.9634 - accuracy: 0.2069 - val_loss: 1.0009 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 29/30                                                                      \n",
      "750/750 - 5s - loss: 1.9607 - accuracy: 0.2078 - val_loss: 1.1390 - val_accuracy: 0.8704\n",
      "\n",
      "Epoch 30/30                                                                      \n",
      "750/750 - 5s - loss: 1.9656 - accuracy: 0.2107 - val_loss: 1.0377 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 1/30                                                                       \n",
      "188/188 - 2s - loss: 2.9158 - accuracy: 0.1046 - val_loss: 2.2894 - val_accuracy: 0.1409\n",
      "\n",
      "Epoch 2/30                                                                       \n",
      "188/188 - 1s - loss: 2.8499 - accuracy: 0.1072 - val_loss: 2.2573 - val_accuracy: 0.1846\n",
      "\n",
      "Epoch 3/30                                                                       \n",
      "188/188 - 1s - loss: 2.7999 - accuracy: 0.1117 - val_loss: 2.2159 - val_accuracy: 0.2384\n",
      "\n",
      "Epoch 4/30                                                                       \n",
      "188/188 - 1s - loss: 2.7330 - accuracy: 0.1189 - val_loss: 2.1800 - val_accuracy: 0.2762\n",
      "\n",
      "Epoch 5/30                                                                       \n",
      "188/188 - 1s - loss: 2.6938 - accuracy: 0.1214 - val_loss: 2.1445 - val_accuracy: 0.3122\n",
      "\n",
      "Epoch 6/30                                                                       \n",
      "188/188 - 1s - loss: 2.6487 - accuracy: 0.1261 - val_loss: 2.1125 - val_accuracy: 0.3420\n",
      "\n",
      "Epoch 7/30                                                                       \n",
      "188/188 - 1s - loss: 2.6034 - accuracy: 0.1312 - val_loss: 2.0867 - val_accuracy: 0.3656\n",
      "\n",
      "Epoch 8/30                                                                       \n",
      "188/188 - 1s - loss: 2.5705 - accuracy: 0.1366 - val_loss: 2.0606 - val_accuracy: 0.3888\n",
      "\n",
      "Epoch 9/30                                                                       \n",
      "188/188 - 1s - loss: 2.5346 - accuracy: 0.1402 - val_loss: 2.0380 - val_accuracy: 0.4057\n",
      "\n",
      "Epoch 10/30                                                                      \n",
      "188/188 - 1s - loss: 2.5063 - accuracy: 0.1445 - val_loss: 2.0154 - val_accuracy: 0.4221\n",
      "\n",
      "Epoch 11/30                                                                      \n",
      "188/188 - 1s - loss: 2.4787 - accuracy: 0.1503 - val_loss: 1.9956 - val_accuracy: 0.4342\n",
      "\n",
      "Epoch 12/30                                                                      \n",
      "188/188 - 1s - loss: 2.4614 - accuracy: 0.1501 - val_loss: 1.9742 - val_accuracy: 0.4469\n",
      "\n",
      "Epoch 13/30                                                                      \n",
      "188/188 - 1s - loss: 2.4251 - accuracy: 0.1590 - val_loss: 1.9569 - val_accuracy: 0.4541\n",
      "\n",
      "Epoch 14/30                                                                      \n",
      "188/188 - 1s - loss: 2.4057 - accuracy: 0.1619 - val_loss: 1.9377 - val_accuracy: 0.4685\n",
      "\n",
      "Epoch 15/30                                                                      \n",
      "188/188 - 1s - loss: 2.3782 - accuracy: 0.1652 - val_loss: 1.9248 - val_accuracy: 0.4701\n",
      "\n",
      "Epoch 16/30                                                                      \n",
      "188/188 - 1s - loss: 2.3594 - accuracy: 0.1694 - val_loss: 1.9100 - val_accuracy: 0.4812\n",
      "\n",
      "Epoch 17/30                                                                      \n",
      "188/188 - 1s - loss: 2.3464 - accuracy: 0.1759 - val_loss: 1.8962 - val_accuracy: 0.4886\n",
      "\n",
      "Epoch 18/30                                                                      \n",
      "188/188 - 1s - loss: 2.3241 - accuracy: 0.1786 - val_loss: 1.8822 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 19/30                                                                      \n",
      "188/188 - 1s - loss: 2.3083 - accuracy: 0.1841 - val_loss: 1.8693 - val_accuracy: 0.5008\n",
      "\n",
      "Epoch 20/30                                                                      \n",
      "188/188 - 1s - loss: 2.3032 - accuracy: 0.1857 - val_loss: 1.8568 - val_accuracy: 0.5083\n",
      "\n",
      "Epoch 21/30                                                                      \n",
      "188/188 - 1s - loss: 2.2898 - accuracy: 0.1857 - val_loss: 1.8460 - val_accuracy: 0.5178\n",
      "\n",
      "Epoch 22/30                                                                      \n",
      "188/188 - 1s - loss: 2.2669 - accuracy: 0.1932 - val_loss: 1.8324 - val_accuracy: 0.5268\n",
      "\n",
      "Epoch 23/30                                                                      \n",
      "188/188 - 1s - loss: 2.2590 - accuracy: 0.1934 - val_loss: 1.8220 - val_accuracy: 0.5313\n",
      "\n",
      "Epoch 24/30                                                                      \n",
      "188/188 - 1s - loss: 2.2423 - accuracy: 0.1984 - val_loss: 1.8121 - val_accuracy: 0.5342\n",
      "\n",
      "Epoch 25/30                                                                      \n",
      "188/188 - 1s - loss: 2.2343 - accuracy: 0.2015 - val_loss: 1.8008 - val_accuracy: 0.5435\n",
      "\n",
      "Epoch 26/30                                                                      \n",
      "188/188 - 1s - loss: 2.2216 - accuracy: 0.2074 - val_loss: 1.7892 - val_accuracy: 0.5485\n",
      "\n",
      "Epoch 27/30                                                                      \n",
      "188/188 - 1s - loss: 2.2088 - accuracy: 0.2109 - val_loss: 1.7791 - val_accuracy: 0.5534\n",
      "\n",
      "Epoch 28/30                                                                      \n",
      "188/188 - 1s - loss: 2.1995 - accuracy: 0.2115 - val_loss: 1.7706 - val_accuracy: 0.5602\n",
      "\n",
      "Epoch 29/30                                                                      \n",
      "188/188 - 1s - loss: 2.1872 - accuracy: 0.2145 - val_loss: 1.7620 - val_accuracy: 0.5622\n",
      "\n",
      "Epoch 30/30                                                                      \n",
      "188/188 - 1s - loss: 2.1815 - accuracy: 0.2159 - val_loss: 1.7534 - val_accuracy: 0.5638\n",
      "\n",
      "Epoch 1/40                                                                       \n",
      "375/375 - 2s - loss: 2.3924 - accuracy: 0.1116 - val_loss: 2.2711 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 2/40                                                                       \n",
      "375/375 - 2s - loss: 2.3006 - accuracy: 0.1171 - val_loss: 2.2732 - val_accuracy: 0.1361\n",
      "\n",
      "Epoch 3/40                                                                       \n",
      "375/375 - 2s - loss: 2.2962 - accuracy: 0.1210 - val_loss: 2.2631 - val_accuracy: 0.2284\n",
      "\n",
      "Epoch 4/40                                                                       \n",
      "375/375 - 2s - loss: 2.2931 - accuracy: 0.1266 - val_loss: 2.2462 - val_accuracy: 0.2672\n",
      "\n",
      "Epoch 5/40                                                                       \n",
      "375/375 - 2s - loss: 2.2887 - accuracy: 0.1291 - val_loss: 2.2294 - val_accuracy: 0.3033\n",
      "\n",
      "Epoch 6/40                                                                       \n",
      "375/375 - 2s - loss: 2.2817 - accuracy: 0.1354 - val_loss: 2.2024 - val_accuracy: 0.3643\n",
      "\n",
      "Epoch 7/40                                                                       \n",
      "375/375 - 2s - loss: 2.2763 - accuracy: 0.1374 - val_loss: 2.1801 - val_accuracy: 0.3267\n",
      "\n",
      "Epoch 8/40                                                                       \n",
      "375/375 - 2s - loss: 2.2685 - accuracy: 0.1405 - val_loss: 2.1499 - val_accuracy: 0.3601\n",
      "\n",
      "Epoch 9/40                                                                       \n",
      "375/375 - 2s - loss: 2.2631 - accuracy: 0.1465 - val_loss: 2.1385 - val_accuracy: 0.3408\n",
      "\n",
      "Epoch 10/40                                                                      \n",
      "375/375 - 2s - loss: 2.2552 - accuracy: 0.1479 - val_loss: 2.1133 - val_accuracy: 0.3907\n",
      "\n",
      "Epoch 11/40                                                                      \n",
      "375/375 - 2s - loss: 2.2531 - accuracy: 0.1473 - val_loss: 2.1045 - val_accuracy: 0.3899\n",
      "\n",
      "Epoch 12/40                                                                      \n",
      "375/375 - 2s - loss: 2.2507 - accuracy: 0.1473 - val_loss: 2.0974 - val_accuracy: 0.3608\n",
      "\n",
      "Epoch 13/40                                                                      \n",
      "375/375 - 2s - loss: 2.2415 - accuracy: 0.1513 - val_loss: 2.0618 - val_accuracy: 0.3498\n",
      "\n",
      "Epoch 14/40                                                                      \n",
      "375/375 - 2s - loss: 2.2378 - accuracy: 0.1515 - val_loss: 2.0587 - val_accuracy: 0.3633\n",
      "\n",
      "Epoch 15/40                                                                      \n",
      "375/375 - 2s - loss: 2.2318 - accuracy: 0.1524 - val_loss: 2.0343 - val_accuracy: 0.3875\n",
      "\n",
      "Epoch 16/40                                                                      \n",
      "375/375 - 2s - loss: 2.2228 - accuracy: 0.1565 - val_loss: 2.0105 - val_accuracy: 0.3483\n",
      "\n",
      "Epoch 17/40                                                                      \n",
      "375/375 - 2s - loss: 2.2140 - accuracy: 0.1557 - val_loss: 1.9872 - val_accuracy: 0.3682\n",
      "\n",
      "Epoch 18/40                                                                      \n",
      "375/375 - 2s - loss: 2.2091 - accuracy: 0.1609 - val_loss: 1.9745 - val_accuracy: 0.3748\n",
      "\n",
      "Epoch 19/40                                                                      \n",
      "375/375 - 2s - loss: 2.2105 - accuracy: 0.1555 - val_loss: 1.9889 - val_accuracy: 0.3725\n",
      "\n",
      "Epoch 20/40                                                                      \n",
      "375/375 - 2s - loss: 2.2159 - accuracy: 0.1555 - val_loss: 1.9975 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 21/40                                                                      \n",
      "375/375 - 2s - loss: 2.2137 - accuracy: 0.1541 - val_loss: 1.9854 - val_accuracy: 0.3534\n",
      "\n",
      "Epoch 22/40                                                                      \n",
      "375/375 - 2s - loss: 2.2084 - accuracy: 0.1567 - val_loss: 1.9769 - val_accuracy: 0.3714\n",
      "\n",
      "Epoch 23/40                                                                      \n",
      "375/375 - 2s - loss: 2.2130 - accuracy: 0.1571 - val_loss: 1.9979 - val_accuracy: 0.3868\n",
      "\n",
      "Epoch 24/40                                                                      \n",
      "375/375 - 2s - loss: 2.2178 - accuracy: 0.1536 - val_loss: 2.0040 - val_accuracy: 0.3718\n",
      "\n",
      "Epoch 25/40                                                                      \n",
      "375/375 - 2s - loss: 2.2145 - accuracy: 0.1555 - val_loss: 1.9958 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 26/40                                                                      \n",
      "375/375 - 2s - loss: 2.2155 - accuracy: 0.1531 - val_loss: 1.9940 - val_accuracy: 0.3609\n",
      "\n",
      "Epoch 27/40                                                                      \n",
      "375/375 - 2s - loss: 2.2155 - accuracy: 0.1546 - val_loss: 2.0014 - val_accuracy: 0.3467\n",
      "\n",
      "Epoch 28/40                                                                      \n",
      "375/375 - 2s - loss: 2.2179 - accuracy: 0.1527 - val_loss: 1.9983 - val_accuracy: 0.3257\n",
      "\n",
      "Epoch 29/40                                                                      \n",
      "375/375 - 2s - loss: 2.2076 - accuracy: 0.1563 - val_loss: 1.9768 - val_accuracy: 0.3556\n",
      "\n",
      "Epoch 30/40                                                                      \n",
      "375/375 - 2s - loss: 2.2014 - accuracy: 0.1573 - val_loss: 1.9670 - val_accuracy: 0.3654\n",
      "\n",
      "Epoch 31/40                                                                      \n",
      "375/375 - 2s - loss: 2.2065 - accuracy: 0.1548 - val_loss: 1.9778 - val_accuracy: 0.4164\n",
      "\n",
      "Epoch 32/40                                                                      \n",
      "375/375 - 2s - loss: 2.2044 - accuracy: 0.1567 - val_loss: 1.9756 - val_accuracy: 0.3702\n",
      "\n",
      "Epoch 33/40                                                                      \n",
      "375/375 - 2s - loss: 2.2141 - accuracy: 0.1517 - val_loss: 2.0006 - val_accuracy: 0.3485\n",
      "\n",
      "Epoch 34/40                                                                      \n",
      "375/375 - 2s - loss: 2.2207 - accuracy: 0.1517 - val_loss: 2.0020 - val_accuracy: 0.3634\n",
      "\n",
      "Epoch 35/40                                                                      \n",
      "375/375 - 2s - loss: 2.2135 - accuracy: 0.1516 - val_loss: 1.9854 - val_accuracy: 0.3696\n",
      "\n",
      "Epoch 36/40                                                                      \n",
      "375/375 - 2s - loss: 2.2105 - accuracy: 0.1524 - val_loss: 1.9846 - val_accuracy: 0.3452\n",
      "\n",
      "Epoch 37/40                                                                      \n",
      "375/375 - 2s - loss: 2.2132 - accuracy: 0.1558 - val_loss: 1.9940 - val_accuracy: 0.3324\n",
      "\n",
      "Epoch 38/40                                                                      \n",
      "375/375 - 2s - loss: 2.2222 - accuracy: 0.1475 - val_loss: 2.0120 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 39/40                                                                      \n",
      "375/375 - 2s - loss: 2.2205 - accuracy: 0.1501 - val_loss: 2.0098 - val_accuracy: 0.3658\n",
      "\n",
      "Epoch 40/40                                                                      \n",
      "375/375 - 2s - loss: 2.2175 - accuracy: 0.1513 - val_loss: 2.0088 - val_accuracy: 0.3527\n",
      "\n",
      "Epoch 1/20                                                                       \n",
      "750/750 - 5s - loss: 2.0556 - accuracy: 0.3070 - val_loss: 0.9667 - val_accuracy: 0.7542\n",
      "\n",
      "Epoch 2/20                                                                       \n",
      "750/750 - 5s - loss: 1.3601 - accuracy: 0.5461 - val_loss: 0.7151 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 3/20                                                                       \n",
      "750/750 - 5s - loss: 1.1031 - accuracy: 0.6397 - val_loss: 0.5982 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 4/20                                                                       \n",
      "750/750 - 5s - loss: 0.9696 - accuracy: 0.6862 - val_loss: 0.5243 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 5/20                                                                       \n",
      "750/750 - 5s - loss: 0.8889 - accuracy: 0.7136 - val_loss: 0.4823 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 6/20                                                                       \n",
      "750/750 - 5s - loss: 0.8278 - accuracy: 0.7371 - val_loss: 0.4518 - val_accuracy: 0.8754\n",
      "\n",
      "Epoch 7/20                                                                       \n",
      "750/750 - 5s - loss: 0.7820 - accuracy: 0.7526 - val_loss: 0.4279 - val_accuracy: 0.8802\n",
      "\n",
      "Epoch 8/20                                                                       \n",
      "750/750 - 6s - loss: 0.7512 - accuracy: 0.7626 - val_loss: 0.4117 - val_accuracy: 0.8835\n",
      "\n",
      "Epoch 9/20                                                                       \n",
      "750/750 - 7s - loss: 0.7254 - accuracy: 0.7699 - val_loss: 0.3998 - val_accuracy: 0.8852\n",
      "\n",
      "Epoch 10/20                                                                      \n",
      "750/750 - 8s - loss: 0.7045 - accuracy: 0.7781 - val_loss: 0.3883 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 11/20                                                                      \n",
      "750/750 - 10s - loss: 0.6914 - accuracy: 0.7851 - val_loss: 0.3789 - val_accuracy: 0.8897\n",
      "\n",
      "Epoch 12/20                                                                      \n",
      "750/750 - 8s - loss: 0.6786 - accuracy: 0.7894 - val_loss: 0.3720 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 13/20                                                                      \n",
      "750/750 - 6s - loss: 0.6602 - accuracy: 0.7956 - val_loss: 0.3665 - val_accuracy: 0.8934\n",
      "\n",
      "Epoch 14/20                                                                      \n",
      "750/750 - 6s - loss: 0.6466 - accuracy: 0.7997 - val_loss: 0.3606 - val_accuracy: 0.8953\n",
      "\n",
      "Epoch 15/20                                                                      \n",
      "750/750 - 6s - loss: 0.6355 - accuracy: 0.8058 - val_loss: 0.3561 - val_accuracy: 0.8953\n",
      "\n",
      "Epoch 16/20                                                                      \n",
      "750/750 - 6s - loss: 0.6257 - accuracy: 0.8080 - val_loss: 0.3508 - val_accuracy: 0.8975\n",
      "\n",
      "Epoch 17/20                                                                      \n",
      "750/750 - 6s - loss: 0.6230 - accuracy: 0.8082 - val_loss: 0.3471 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 18/20                                                                      \n",
      "750/750 - 6s - loss: 0.6109 - accuracy: 0.8137 - val_loss: 0.3453 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 19/20                                                                      \n",
      "750/750 - 6s - loss: 0.6063 - accuracy: 0.8144 - val_loss: 0.3428 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 20/20                                                                      \n",
      "750/750 - 6s - loss: 0.5972 - accuracy: 0.8170 - val_loss: 0.3396 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 1/20                                                                       \n",
      "750/750 - 5s - loss: 0.2486 - accuracy: 0.9239 - val_loss: 0.1470 - val_accuracy: 0.9570\n",
      "\n",
      "Epoch 2/20                                                                       \n",
      "750/750 - 5s - loss: 0.1384 - accuracy: 0.9566 - val_loss: 0.1066 - val_accuracy: 0.9689\n",
      "\n",
      "Epoch 3/20                                                                       \n",
      "750/750 - 5s - loss: 0.1048 - accuracy: 0.9665 - val_loss: 0.1251 - val_accuracy: 0.9640\n",
      "\n",
      "Epoch 4/20                                                                       \n",
      "750/750 - 5s - loss: 0.0935 - accuracy: 0.9705 - val_loss: 0.0887 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 5/20                                                                       \n",
      "750/750 - 5s - loss: 0.0841 - accuracy: 0.9730 - val_loss: 0.0821 - val_accuracy: 0.9756\n",
      "\n",
      "Epoch 6/20                                                                       \n",
      "750/750 - 5s - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.0978 - val_accuracy: 0.9741\n",
      "\n",
      "Epoch 7/20                                                                       \n",
      "750/750 - 5s - loss: 0.0676 - accuracy: 0.9791 - val_loss: 0.0878 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 8/20                                                                       \n",
      "750/750 - 5s - loss: 0.0643 - accuracy: 0.9789 - val_loss: 0.0760 - val_accuracy: 0.9779\n",
      "\n",
      "Epoch 9/20                                                                       \n",
      "750/750 - 5s - loss: 0.0594 - accuracy: 0.9813 - val_loss: 0.0937 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 10/20                                                                      \n",
      "750/750 - 5s - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.1062 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 11/20                                                                      \n",
      "750/750 - 5s - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.0887 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 12/20                                                                      \n",
      "750/750 - 5s - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.1123 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 13/20                                                                      \n",
      "750/750 - 5s - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.0763 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 14/20                                                                      \n",
      "750/750 - 5s - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.0957 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 15/20                                                                      \n",
      "750/750 - 5s - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 16/20                                                                      \n",
      "750/750 - 5s - loss: 0.0403 - accuracy: 0.9865 - val_loss: 0.0893 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 17/20                                                                      \n",
      "750/750 - 5s - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.0955 - val_accuracy: 0.9782\n",
      "\n",
      "Epoch 18/20                                                                      \n",
      "750/750 - 5s - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0863 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 19/20                                                                      \n",
      "750/750 - 5s - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0974 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 20/20                                                                      \n",
      "750/750 - 5s - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0908 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 1/2                                                                        \n",
      "375/375 - 3s - loss: 0.7065 - accuracy: 0.7800 - val_loss: 0.2626 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 2/2                                                                       \n",
      "375/375 - 2s - loss: 0.4797 - accuracy: 0.8608 - val_loss: 0.2318 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 1/5                                                                       \n",
      "375/375 - 4s - loss: 1.2683 - accuracy: 0.5810 - val_loss: 0.4848 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 2/5                                                                       \n",
      "375/375 - 4s - loss: 0.9949 - accuracy: 0.6683 - val_loss: 0.3564 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 3/5                                                                       \n",
      "375/375 - 4s - loss: 0.8873 - accuracy: 0.7009 - val_loss: 0.2979 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 4/5                                                                       \n",
      "375/375 - 4s - loss: 0.8122 - accuracy: 0.7228 - val_loss: 0.2581 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 5/5                                                                       \n",
      "375/375 - 4s - loss: 0.7528 - accuracy: 0.7444 - val_loss: 0.2200 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 1/10                                                                      \n",
      "188/188 - 3s - loss: 1.0396 - accuracy: 0.6518 - val_loss: 0.7523 - val_accuracy: 0.7958\n",
      "\n",
      "Epoch 2/10                                                                      \n",
      "188/188 - 3s - loss: 0.7404 - accuracy: 0.7741 - val_loss: 0.3058 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 3/10                                                                      \n",
      "188/188 - 3s - loss: 0.6382 - accuracy: 0.8101 - val_loss: 0.3862 - val_accuracy: 0.8961\n",
      "\n",
      "Epoch 4/10                                                                      \n",
      "188/188 - 3s - loss: 0.5913 - accuracy: 0.8261 - val_loss: 0.3181 - val_accuracy: 0.8987\n",
      "\n",
      "Epoch 5/10                                                                      \n",
      "188/188 - 3s - loss: 0.5675 - accuracy: 0.8369 - val_loss: 0.2490 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 6/10                                                                      \n",
      "188/188 - 3s - loss: 0.5424 - accuracy: 0.8438 - val_loss: 0.2918 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 7/10                                                                      \n",
      "188/188 - 3s - loss: 0.5202 - accuracy: 0.8509 - val_loss: 0.2311 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 8/10                                                                      \n",
      "188/188 - 3s - loss: 0.5058 - accuracy: 0.8572 - val_loss: 0.2297 - val_accuracy: 0.9365\n",
      "\n",
      "Epoch 9/10                                                                      \n",
      "188/188 - 3s - loss: 0.4902 - accuracy: 0.8612 - val_loss: 0.2409 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 10/10                                                                     \n",
      "188/188 - 3s - loss: 0.4764 - accuracy: 0.8648 - val_loss: 0.3544 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 1/20                                                                      \n",
      "1500/1500 - 7s - loss: 1.6632 - accuracy: 0.4570 - val_loss: 0.7198 - val_accuracy: 0.8007\n",
      "\n",
      "Epoch 2/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.9706 - accuracy: 0.6855 - val_loss: 0.5302 - val_accuracy: 0.8525\n",
      "\n",
      "Epoch 3/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.7954 - accuracy: 0.7476 - val_loss: 0.4544 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 4/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.7125 - accuracy: 0.7740 - val_loss: 0.4103 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 5/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.6582 - accuracy: 0.7937 - val_loss: 0.3823 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 6/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.6102 - accuracy: 0.8087 - val_loss: 0.3632 - val_accuracy: 0.8930\n",
      "\n",
      "Epoch 7/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.5848 - accuracy: 0.8172 - val_loss: 0.3464 - val_accuracy: 0.8980\n",
      "\n",
      "Epoch 8/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.5592 - accuracy: 0.8267 - val_loss: 0.3333 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 9/20                                                                      \n",
      "1500/1500 - 7s - loss: 0.5409 - accuracy: 0.8327 - val_loss: 0.3236 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 10/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.5281 - accuracy: 0.8381 - val_loss: 0.3139 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 11/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.5130 - accuracy: 0.8426 - val_loss: 0.3053 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 12/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4980 - accuracy: 0.8461 - val_loss: 0.2991 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 13/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4894 - accuracy: 0.8503 - val_loss: 0.2937 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 14/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4762 - accuracy: 0.8529 - val_loss: 0.2881 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 15/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4719 - accuracy: 0.8551 - val_loss: 0.2822 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 16/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4596 - accuracy: 0.8608 - val_loss: 0.2777 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 17/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4529 - accuracy: 0.8619 - val_loss: 0.2741 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 18/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4491 - accuracy: 0.8618 - val_loss: 0.2706 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 19/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4396 - accuracy: 0.8645 - val_loss: 0.2667 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 20/20                                                                     \n",
      "1500/1500 - 7s - loss: 0.4349 - accuracy: 0.8671 - val_loss: 0.2647 - val_accuracy: 0.9210\n",
      "\n",
      "100%|| 10/10 [12:33<00:00, 75.35s/trial, best loss: -0.981166660785675]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=trials,\n",
    "                                          notebook_name='SkeletonANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9832\n",
      "[0.0726236030459404, 0.9832000136375427]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 2, 'Activation_1': 0, 'Dense': 1, 'Dense_1': 2, 'Dropout': 0.1904090881738011, 'Dropout_1': 0.08063845654367285, 'batch_size': 1, 'choiceval': 0, 'epochs': 3, 'lr': 2, 'lr_1': 3, 'lr_2': 2}\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, X_test, Y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 471,434\n",
      "Trainable params: 470,154\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show the structure of your model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trials.best_trial['result']\n",
    "del res['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume you have stored the training history in the variable \"history\"\n",
    "# Show the learning curves\n",
    "pd.DataFrame(res).plot(figsize=(12, 8))\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('mnist.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and evaluate it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0726236030459404, 0.9832000136375427]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"mnist.h5\")\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short report\n",
    "\n",
    "Please write briefly how you build and train the model. Please include the decisions you made, such as why you use x number layers, and the difficulties you met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to built our Model we initially had to split the data into training and test data which was in line with our previous excercises and in line with the suggested preparation per the presentaions of Haozhe for practical 3.\n",
    "\n",
    "As a second step we built the skeleton for the Neural Network which should classify the pictures and a list of options which we can give an optimization program to optimize the model. The main challenges we encountered there were the following\n",
    "-\tChoosing an appropriate amount of layers\n",
    "-\tChoosing an appropriate amount of neurons\n",
    "-\tChosing an appropriate activation function per a certain layer\n",
    "-\tChoosing the right optimization method.\n",
    "-\tChoosing the right validation method\n",
    "In order to optimize our model we therefore picked Hyperas to assess the best option amongst a list of options which we picked as we knew them from the Lecture or via internet research. To do so we would use the Hyperas Library. \n",
    "By using Hyperas a specific space can be explored much better. As such we had first to pick a list of options and then run the options through the optimization program which we wrote. In order to solve these problems we performed the following:\n",
    "\n",
    "-\tLayers: (.Dense) As a first step RandomCV has been used to define the amount of hidden layers. It turned out that by using 3 hidden layers the validation error started to increase which indicates overfitting. Therefore we eventually picked 2 layers\n",
    "\n",
    "-\tNeurons (.Dense({Choice()}): To decide the amount of Neurons we want to try out with hyperas, we tried a couple of different sizes, where we started with a range of about 1024 Neurons for the first layer and a bit of a lower size for the second layer. This did initially not provide good performances. After some tries we figured out that an amount between 256 and 512 may perform the best for the first layer and 32, 64 and 128 for the second layer. From our own research of literature we ntoed that the number of neurons to be tried should be binary numbers (due to the binary hardware architecture this gives the best results).\n",
    "\n",
    "-\tActivation Function: we used the most common ones relu, selu and elu which provided us with the bet result.\n",
    "\n",
    "-\tChoosing the right Optimization Option: We tried out Gradient Decent initially but figured out that it took too much time to calculate, while eventually BatchNormalization provided a good performance improvement vs. time relationship\n",
    "\n",
    "-\tChoosing the right validation method: We decided to choose between adam, sgd and rmsprop as we have read in the literature that these opimizers are state of the art\n",
    "\n",
    "After trying out several of the above options the result was the model which we put onto Github, where we run the Hyperas code and picked the model architecture which had the highest performance accuracy. Thereby we reached an accuracy of 98%. The output also shows the different parameters of the model, by providing the index of a certain option type (e.g. activation: 2 means the third element of the provided optimization options which is in our case elu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}