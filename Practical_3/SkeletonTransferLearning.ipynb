{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkeletonTransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dijRSzFiCSkL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "per-LT3NCSj8"
      },
      "source": [
        "# Practical 3: Transfer Learning\n",
        "\n",
        "This is the second task of Practical 3. You will use transfer learning to build a convolutional neural network to tackle the CIFAR-10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html). \n",
        "You could select an existing trained model (VGG16 excluded) from Keras (https://keras.io/api/applications/) and fine-tune it to solve the classification problem of CIFAR-10. \n",
        "\n",
        "We will mark your code based on the accuracy of your model. You should try to get **at least 80%** accuracy on this dataset. Don't forget to save and check in your model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dijRSzFiCSkL"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Kw8MZECSkM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nj29DDsTCSkN",
        "outputId": "b27b0438-27fe-4f6b-90d5-1a751874e45d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6bS4O6sECSkO",
        "outputId": "fecedc5e-159f-492b-df3a-28c4d01a1527"
      },
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4xwgi6CSkQ"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "In this block, you will prepare the data for the training, such as apply the preprocess function of your selected model and perform data augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkjM4O0ECSkQ"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "\n",
        "# resnet preprocess\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)\n",
        "\n",
        "# one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# get validation dataset\n",
        "np.random.seed(42) # we set the random seed to make sure everytime the data is shuffled in the same way \n",
        "shuffled_indices = np.random.permutation(X_train.shape[0])\n",
        "X_valid, X_train = X_train[shuffled_indices[:5000]], X_train[shuffled_indices[5000:]]\n",
        "y_valid, y_train = y_train[shuffled_indices[:5000]], y_train[shuffled_indices[5000:]]\n",
        "\n",
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "\t\trotation_range=40,\n",
        "\t\tzoom_range=0.15,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\thorizontal_flip=True,\n",
        "\t\tfill_mode=\"nearest\")\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "train_data_generator = datagen.flow(X_train, y_train, batch_size=32)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rwPNPVeCSkR"
      },
      "source": [
        "## Build and train the model\n",
        "\n",
        "Build and train your model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVHXJcSvCSkS"
      },
      "source": [
        "resNet50_model = tf.keras.applications.ResNet50(include_top=False, input_shape=(256, 256, 3), weights='imagenet')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPFlvFPsCSkT",
        "outputId": "646df49d-3776-441c-fda3-fddafd3b2942"
      },
      "source": [
        "# show the structure of your model\n",
        "resNet50_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKeRZh6kCSkU"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "# upsampling is needed because Resnet50 works best with images greater than 200 x 200\n",
        "model.add(keras.layers.UpSampling2D((8,8))) # Size 256 x 256\n",
        "\n",
        "model.add(resNet50_model)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512, activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Freeze the resNet50 layers but retrain the last block\n",
        "for layer in resNet50_model.layers[:-32]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzdaNBehCSkV"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-5), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_NsFuBMCSkV",
        "outputId": "49f0097c-6b4e-4259-dcc9-6e4e194c3047"
      },
      "source": [
        "history = model.fit(train_data_generator, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 410s 287ms/step - loss: 1.5843 - accuracy: 0.4761 - val_loss: 0.6510 - val_accuracy: 0.7950\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 403s 286ms/step - loss: 0.8694 - accuracy: 0.7073 - val_loss: 0.5069 - val_accuracy: 0.8374\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 403s 287ms/step - loss: 0.7213 - accuracy: 0.7618 - val_loss: 0.4505 - val_accuracy: 0.8572\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 403s 287ms/step - loss: 0.6264 - accuracy: 0.7978 - val_loss: 0.4236 - val_accuracy: 0.8684\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 403s 287ms/step - loss: 0.5664 - accuracy: 0.8164 - val_loss: 0.3558 - val_accuracy: 0.8864\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 403s 286ms/step - loss: 0.5204 - accuracy: 0.8307 - val_loss: 0.3999 - val_accuracy: 0.8800\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 403s 287ms/step - loss: 0.4764 - accuracy: 0.8454 - val_loss: 0.3496 - val_accuracy: 0.8946\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 403s 286ms/step - loss: 0.4404 - accuracy: 0.8554 - val_loss: 0.3464 - val_accuracy: 0.8896\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 403s 286ms/step - loss: 0.4217 - accuracy: 0.8651 - val_loss: 0.3645 - val_accuracy: 0.8910\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 402s 286ms/step - loss: 0.4009 - accuracy: 0.8709 - val_loss: 0.3311 - val_accuracy: 0.9010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjYcalWqE9l2",
        "outputId": "f0c7d7c4-7cc5-41f1-9082-29a5c56356a7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) (None, None, None, None)  0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               67109376  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 90,766,602\n",
            "Trainable params: 82,153,610\n",
            "Non-trainable params: 8,612,992\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46W5NS5ICSkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "f615cbc5-3eed-4bef-fbbc-1962104d4c41"
      },
      "source": [
        "# Assume you have stored the training history in the variable \"history\"\n",
        "# Show the learning curves\n",
        "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9ERAP0QCSkW"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WET9mtEMCSkW"
      },
      "source": [
        "model.save('cifar10.h5') "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w09J3IzRId7c",
        "outputId": "79a6f9fa-51b0-4203-b4f3-9cc01b6692d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_-JG3gYFixy"
      },
      "source": [
        "model.save(F\"/content/gdrive/My Drive/cifar10.h5\") "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvz-ZViACSkX"
      },
      "source": [
        "## Load the model and evaluate it on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du6UXSiPCSkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4235b0f3-6772-4436-b6b6-f1c908565c2c"
      },
      "source": [
        "model = keras.models.load_model(\"cifar10.h5\")\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 55s 174ms/step - loss: 0.3481 - accuracy: 0.8981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3481239974498749, 0.8981000185012817]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmTU2cVjCSkX"
      },
      "source": [
        "## Short report\n",
        "\n",
        "Please write briefly how you build and train the model. Please include the decisions you made, such as how you decide the number of layers reused from the selected model, and the difficulties you met."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOkpUSSQCSkY"
      },
      "source": [
        "The main challenges with this task were the following:\n",
        "- Picking a model to optimize and use Transfer Learning in order to adapt to the data accordingly\n",
        "- The size of the model, which made it difficult to use a method such as Hyperas (takes to much time). Therefore optimizing the model had to be more focused on specific parts\n",
        "- Having enough data to train and test the model\n",
        "\n",
        "In order to tackle these challenges we performed the following:\n",
        "- Picking a model: From the Keras library we decided to pick a model which does not have a too big size (Amount of parameters to train). Which is why we eventually ended up choosing ResNet50. The model also had a reasonably good performance which is why we went with this option.\n",
        "- Having enough Data to optimize the model: The provided dataset was relatively small. However, in order to optimize a neural network we would need a relatively high amount of data so that the model can fine tune its parameters. In order to increase the amount of data we therefore used data augumentation, this means we artificially created new data based on the properties of the existing data which would serve as the training data. After increasing the amount of data directly we applied the augumented data set to train our model by using the keras library ImageDataGenerator.\n",
        "- Understanding how to optimize the Model: For this we had to perform research in related literature, where we noted that:\n",
        "    - optimizing a model of large scale requires to train the model at certain layers rather than training all layers and neurons of a network. For this purpose we different numbers of layers to freeze while the remaining layers were optimized similar to the Hyperas method as done in the first part of the exercise. After some trials we figured out that we should train only the last 32 layers of the model, which did not consume significant amount of time in order to fine tune the model parameters (neurons, layers, activation functions per layer etc.)\n",
        "    - The size of the model vs. the size of the input values represented a problem as the input values were not large enough for the model to increase its performance. As such we had to perform so-called upscaling. Without upscaling our model did not quite reach the accuracy as high as required. Upscaling is used in order to artificially increase the size of a certain data point in the testing set. i.e. in this case the size of a picture had to be increased to enhance the performance of the model. After which we could see an improvement in accuracy.\n",
        "    - As we have removed ResNet50's fully connected layer, we tried to add our own fully connected layers on top of the existing model. Starting with only one hidden layer with just 128 neurons showed not promising results: The model was clearly underfitting reaching only an test accuracy of 60%. We started by adding another hidden layer and in addition to that added a normalization layer and a dropout layer to each of the hidden layers to prevent overfitting.\n",
        "\n",
        "After applying all these steps we finally reached a test accuracy of 89%."
      ]
    }
  ]
}